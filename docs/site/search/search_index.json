{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "Welcome to MkDocs", "text": "<p>For full documentation visit mkdocs.org.</p>"}, {"location": "#commands", "title": "Commands", "text": "<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"}, {"location": "#project-layout", "title": "Project layout", "text": "<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    docs.md       # Other markdown pages, images and other files.\n</code></pre>"}, {"location": "errors/", "title": "Errors", "text": ""}, {"location": "errors/#inferences.errors-classes", "title": "Classes", "text": ""}, {"location": "errors/#inferences.errors.DatasetError", "title": "<code>DatasetError</code>", "text": "<p>An error raised when the dataset is invalid or incomplete</p> Source code in <code>inferences/errors.py</code> <pre><code>class DatasetError(Exception):\n    \"\"\"An error raised when the dataset is invalid or incomplete\"\"\"\n\n    def __init__(self, errors: Union[ValidationError, List[ValidationError]]):\n        self.errors: List[ValidationError] = errors if isinstance(errors, list) else [errors]\n\n    def __str__(self) -&gt; str:\n        return \"\\n\".join(map(str, self.errors))\n</code></pre>"}, {"location": "errors/#inferences.errors.EmbeddingVectorSizeMismatch", "title": "<code>EmbeddingVectorSizeMismatch</code>", "text": "<p>An error raised when there is an embedding feature with multiple different vector lengths</p> Source code in <code>inferences/errors.py</code> <pre><code>class EmbeddingVectorSizeMismatch(ValidationError):\n    \"\"\"An error raised when there is an embedding feature with multiple different\n    vector lengths\"\"\"\n\n    def __init__(\n        self, embedding_feature_name: str, vector_column_name: str, vector_lengths: List[int]\n    ) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n        self.vector_column_name = vector_column_name\n        self.vector_lengths = vector_lengths\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Embedding vectors for an embedding feature must be of same length. \"\n            f\"Found vectors with lengths of {self.vector_lengths} \"\n            f\"{self.embedding_feature_name}.vector = {self.vector_column_name}\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.InvalidColumnType", "title": "<code>InvalidColumnType</code>", "text": "<p>An error raised when the column type is invalid</p> Source code in <code>inferences/errors.py</code> <pre><code>class InvalidColumnType(ValidationError):\n    \"\"\"An error raised when the column type is invalid\"\"\"\n\n    def __init__(self, error_msgs: Iterable[str]) -&gt; None:\n        self.error_msgs = error_msgs\n\n    def error_message(self) -&gt; str:\n        return f\"Invalid column types: {self.error_msgs}\"\n</code></pre>"}, {"location": "errors/#inferences.errors.InvalidEmbeddingReservedName", "title": "<code>InvalidEmbeddingReservedName</code>", "text": "<p>An error raised when there is an embedding feature with a name, i.e. dictionary key, that is reserved</p> Source code in <code>inferences/errors.py</code> <pre><code>class InvalidEmbeddingReservedName(ValidationError):\n    \"\"\"An error raised when there is an embedding feature with a name, i.e. dictionary key,\n    that is reserved\n    \"\"\"\n\n    def __init__(\n        self,\n        reserved_name: str,\n        schema_field: str,\n    ) -&gt; None:\n        self.reserved_name = reserved_name\n        self.schema_field = schema_field\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Embedding feature name '{self.reserved_name}' is reserved and cannot be used. \"\n            f\"This is the case when '{self.schema_field}' is not None.\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.InvalidEmbeddingVectorDataType", "title": "<code>InvalidEmbeddingVectorDataType</code>", "text": "<p>An error raised when there is an embedding feature with a vector of an unsupported data type</p> Source code in <code>inferences/errors.py</code> <pre><code>class InvalidEmbeddingVectorDataType(ValidationError):\n    \"\"\"An error raised when there is an embedding feature with a vector of an unsupported\n    data type\"\"\"\n\n    def __init__(self, embedding_feature_name: str, vector_column_type: str) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n        self.vector_column_type = vector_column_type\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Embedding feature {self.embedding_feature_name} has vector type \"\n            f\"{self.vector_column_type}. Must be list, np.ndarray or pd.Series\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.InvalidEmbeddingVectorSize", "title": "<code>InvalidEmbeddingVectorSize</code>", "text": "<p>An error raised when there is an embedding feature with an invalid vector length</p> Source code in <code>inferences/errors.py</code> <pre><code>class InvalidEmbeddingVectorSize(ValidationError):\n    \"\"\"An error raised when there is an embedding feature with an invalid vector length\"\"\"\n\n    def __init__(\n        self, embedding_feature_name: str, vector_column_name: str, vector_length: int\n    ) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n        self.vector_column_name = vector_column_name\n        self.vector_length = vector_length\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Embedding vectors cannot be less than 2 in size. Found vector\"\n            f\" with size of {self.vector_length}; {self.embedding_feature_name}.vector = \"\n            f\"{self.vector_column_name}\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.InvalidEmbeddingVectorValuesDataType", "title": "<code>InvalidEmbeddingVectorValuesDataType</code>", "text": "<p>An error raised when there is an embedding feature with a vector that has values of an unsupported data type</p> Source code in <code>inferences/errors.py</code> <pre><code>class InvalidEmbeddingVectorValuesDataType(ValidationError):\n    \"\"\"An error raised when there is an embedding feature with a vector that has\n    values of an unsupported data type\"\"\"\n\n    def __init__(self, embedding_feature_name: str, vector_column_name: str, vector: Any) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n        self.vector_column_name = vector_column_name\n        self.vector = vector\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Embedding vector must be a vector of integers and/or floats. Got {self.vector}; \"\n            f\"{self.embedding_feature_name}.vector = {self.vector_column_name}\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.InvalidSchemaError", "title": "<code>InvalidSchemaError</code>", "text": "Source code in <code>inferences/errors.py</code> <pre><code>class InvalidSchemaError(ValidationError):\n    def __repr__(self) -&gt; str:\n        return self.__class__.__name__\n\n    def __init__(self, invalid_props: Iterable[str]) -&gt; None:\n        self.invalid_props = invalid_props\n\n    def error_message(self) -&gt; str:\n        errors_string = \", \".join(map(str, self.invalid_props))\n        return f\"The schema is invalid: {errors_string}.\"\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingColumns", "title": "<code>MissingColumns</code>", "text": "<p>An error raised when the dataset is missing columns specified in the schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingColumns(ValidationError):\n    \"\"\"An error raised when the dataset is missing columns specified in the schema\"\"\"\n\n    def __init__(self, cols: Iterable[str]) -&gt; None:\n        self.missing_cols = cols\n\n    def error_message(self) -&gt; str:\n        return (\n            \"The following columns are declared in the Schema \"\n            \"but are not found in the dataframe: \"\n            f\"{', '.join(map(str, self.missing_cols))}.\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingEmbeddingFeatureColumnNames", "title": "<code>MissingEmbeddingFeatureColumnNames</code>", "text": "<p>An error raised when trying to access an EmbeddingColumnNames config that is absent from the schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingEmbeddingFeatureColumnNames(ValidationError):\n    \"\"\"An error raised when trying to access an EmbeddingColumnNames config that is absent\n    from the schema\"\"\"\n\n    def __init__(self, embedding_feature_name: str) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n\n    def error_message(self) -&gt; str:\n        return f\"Schema is missing embedding_feature_column_names[{self.embedding_feature_name}]\"\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingEmbeddingFeatureLinkToDataColumnName", "title": "<code>MissingEmbeddingFeatureLinkToDataColumnName</code>", "text": "<p>An error raised when trying to access an EmbeddingColumnNames.link_to_data_column_name absent from the schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingEmbeddingFeatureLinkToDataColumnName(ValidationError):\n    \"\"\"An error raised when trying to access an EmbeddingColumnNames.link_to_data_column_name\n    absent from the schema\"\"\"\n\n    def __init__(self, embedding_feature_name: str) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Schema is missing link_to_data_column_name of embedding_feature_column_names\"\n            f\"[{self.embedding_feature_name}]\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingEmbeddingFeatureRawDataColumnName", "title": "<code>MissingEmbeddingFeatureRawDataColumnName</code>", "text": "<p>An error raised when trying to access an EmbeddingColumnNames.raw_data_column_name that is absent from the schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingEmbeddingFeatureRawDataColumnName(ValidationError):\n    \"\"\"An error raised when trying to access an EmbeddingColumnNames.raw_data_column_name\n    that is absent from the schema\"\"\"\n\n    def __init__(self, embedding_feature_name: str) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Schema is missing raw_data_column_name of embedding_feature_column_names\"\n            f\"[{self.embedding_feature_name}]\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingEmbeddingFeatureVectorColumnName", "title": "<code>MissingEmbeddingFeatureVectorColumnName</code>", "text": "<p>An error raised when trying to access an EmbeddingColumnNames.vector_column_name that is absent from the schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingEmbeddingFeatureVectorColumnName(ValidationError):\n    \"\"\"An error raised when trying to access an EmbeddingColumnNames.vector_column_name\n    that is absent from the schema\"\"\"\n\n    def __init__(self, embedding_feature_name: str) -&gt; None:\n        self.embedding_feature_name = embedding_feature_name\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"Schema is missing vector_column_name of embedding_feature_column_names\"\n            f\"[{self.embedding_feature_name}]\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingField", "title": "<code>MissingField</code>", "text": "<p>An error raised when trying to access a field that is absent from the Schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingField(ValidationError):\n    \"\"\"An error raised when trying to access a field that is absent from the Schema\"\"\"\n\n    def __init__(self, field: str) -&gt; None:\n        self.missing_field = field\n\n    def error_message(self) -&gt; str:\n        return f\"Schema is missing {self.missing_field}\"\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingTimestampColumnName", "title": "<code>MissingTimestampColumnName</code>", "text": "<p>An error raised when trying to access a timestamp column that is absent from the schema.</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingTimestampColumnName(ValidationError):\n    \"\"\"\n    An error raised when trying to access a timestamp column that is absent from\n    the schema.\n    \"\"\"\n\n    def error_message(self) -&gt; str:\n        return \"Schema is missing timestamp_column_name.\"\n</code></pre>"}, {"location": "errors/#inferences.errors.MissingVectorColumn", "title": "<code>MissingVectorColumn</code>", "text": "<p>An error raised when the dataset is missing an embedding vector column specified in the schema</p> Source code in <code>inferences/errors.py</code> <pre><code>class MissingVectorColumn(ValidationError):\n    \"\"\"An error raised when the dataset is missing an embedding vector column specified in the\n    schema\"\"\"\n\n    def __init__(self, col: str) -&gt; None:\n        self.missing_col = col\n\n    def error_message(self) -&gt; str:\n        return (\n            f\"The embedding vector column {self.missing_col} is declared in the Schema \"\n            \"but is not found in the data.\"\n        )\n</code></pre>"}, {"location": "errors/#inferences.errors.SchemaError", "title": "<code>SchemaError</code>", "text": "<p>An error raised when the Schema is invalid or incomplete</p> Source code in <code>inferences/errors.py</code> <pre><code>class SchemaError(Exception):\n    \"\"\"An error raised when the Schema is invalid or incomplete\"\"\"\n\n    def __init__(self, errors: Union[ValidationError, List[ValidationError]]):\n        self.errors = errors\n</code></pre>"}, {"location": "errors/#inferences.errors.ValidationError", "title": "<code>ValidationError</code>", "text": "Source code in <code>inferences/errors.py</code> <pre><code>class ValidationError(Exception):\n    def __repr__(self) -&gt; str:\n        return self.__class__.__name__\n\n    def __str__(self) -&gt; str:\n        return self.error_message()\n\n    @abstractmethod\n    def error_message(self) -&gt; str:\n        pass\n</code></pre>"}, {"location": "inferences/", "title": "Inferences", "text": ""}, {"location": "inferences/#inferences.inferences-classes", "title": "Classes", "text": ""}, {"location": "inferences/#inferences.inferences.Inferences", "title": "<code>Inferences</code>", "text": "<p>A dataset to use for analysis using phoenix. Used to construct a phoenix session via px.launch_app</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The pandas dataframe containing the data to analyze</p> required <code>schema</code> <code>Schema</code> <p>the schema of the dataset. Maps dataframe columns to the appropriate model inference dimensions (features, predictions, actuals).</p> required <code>name</code> <code>str</code> <p>The name of the dataset. If not provided, a random name will be generated. Is helpful for identifying the dataset in the application.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dataset</code> <code>Dataset</code> <p>The dataset object that can be used in a phoenix session</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; primary_dataset = px.Inferences(\n&gt;&gt;&gt;    dataframe=production_dataframe, schema=schema, name=\"primary\"\n&gt;&gt;&gt; )\n</code></pre> Source code in <code>inferences/inferences.py</code> <pre><code>class Inferences:\n    \"\"\"\n    A dataset to use for analysis using phoenix.\n    Used to construct a phoenix session via px.launch_app\n\n    Parameters\n    ----------\n    dataframe : pandas.DataFrame\n        The pandas dataframe containing the data to analyze\n    schema : phoenix.Schema\n        the schema of the dataset. Maps dataframe columns to the appropriate\n        model inference dimensions (features, predictions, actuals).\n    name : str, optional\n        The name of the dataset. If not provided, a random name will be generated.\n        Is helpful for identifying the dataset in the application.\n\n    Returns\n    -------\n    dataset : Dataset\n        The dataset object that can be used in a phoenix session\n\n    Examples\n    --------\n    &gt;&gt;&gt; primary_dataset = px.Inferences(\n    &gt;&gt;&gt;    dataframe=production_dataframe, schema=schema, name=\"primary\"\n    &gt;&gt;&gt; )\n    \"\"\"\n\n    _data_file_name: str = \"data.parquet\"\n    _schema_file_name: str = \"schema.json\"\n    _is_persisted: bool = False\n    _is_empty: bool = False\n\n    def __init__(\n        self,\n        dataframe: DataFrame,\n        schema: Union[Schema, SchemaLike],\n        name: Optional[str] = None,\n    ):\n        # allow for schema like objects\n        if not isinstance(schema, Schema):\n            schema = _get_schema_from_unknown_schema_param(schema)\n        errors = validate_dataset_inputs(\n            dataframe=dataframe,\n            schema=schema,\n        )\n        if errors:\n            raise err.DatasetError(errors)\n        dataframe, schema = _parse_dataframe_and_schema(dataframe, schema)\n        dataframe, schema = _normalize_timestamps(\n            dataframe, schema, default_timestamp=Timestamp.utcnow()\n        )\n        dataframe = _sort_dataframe_rows_by_timestamp(dataframe, schema)\n        self.__dataframe: DataFrame = dataframe\n        self.__schema: Schema = schema\n        self.__name: str = (\n            name if name is not None else f\"{GENERATED_DATASET_NAME_PREFIX}{str(uuid.uuid4())}\"\n        )\n        self._is_empty = self.dataframe.empty\n        logger.info(f\"\"\"Dataset: {self.__name} initialized\"\"\")\n\n    def __repr__(self) -&gt; str:\n        return f'&lt;Dataset \"{self.name}\"&gt;'\n\n    @property\n    def dataframe(self) -&gt; DataFrame:\n        return self.__dataframe\n\n    @property\n    def schema(self) -&gt; \"Schema\":\n        return self.__schema\n\n    @property\n    def name(self) -&gt; str:\n        return self.__name\n\n    @classmethod\n    def from_name(cls, name: str) -&gt; \"Inferences\":\n        \"\"\"Retrieves a dataset by name from the file system\"\"\"\n        directory = DATASET_DIR / name\n        df = read_parquet(directory / cls._data_file_name)\n        with open(directory / cls._schema_file_name) as schema_file:\n            schema_json = schema_file.read()\n        schema = Schema.from_json(schema_json)\n        return cls(df, schema, name)\n\n    def to_disc(self) -&gt; None:\n        \"\"\"writes the data and schema to disc\"\"\"\n        directory = DATASET_DIR / self.name\n        directory.mkdir(parents=True, exist_ok=True)\n        self.dataframe.to_parquet(\n            directory / self._data_file_name,\n            allow_truncated_timestamps=True,\n            coerce_timestamps=\"ms\",\n        )\n        schema_json_data = self.schema.to_json()\n        with open(directory / self._schema_file_name, \"w+\") as schema_file:\n            schema_file.write(schema_json_data)\n\n    @classmethod\n    @deprecated(\"Inferences.from_open_inference is deprecated and will be removed.\")\n    def from_open_inference(cls, dataframe: DataFrame) -&gt; \"Inferences\":\n        schema = Schema()\n        column_renaming: Dict[str, str] = {}\n        for group_name, group in groupby(\n            sorted(\n                map(_parse_open_inference_column_name, dataframe.columns),\n                key=lambda column: column.name,\n            ),\n            key=lambda column: column.name,\n        ):\n            open_inference_columns = list(group)\n            if group_name == \"\":\n                column_names_by_category = {\n                    column.category: column.full_name for column in open_inference_columns\n                }\n                schema = replace(\n                    schema,\n                    prediction_id_column_name=column_names_by_category.get(\n                        OpenInferenceCategory.id\n                    ),\n                    timestamp_column_name=column_names_by_category.get(\n                        OpenInferenceCategory.timestamp\n                    ),\n                )\n                continue\n            column_names_by_specifier = {\n                column.specifier: column.full_name for column in open_inference_columns\n            }\n            if group_name == \"response\":\n                response_vector_column_name = column_names_by_specifier.get(\n                    OpenInferenceSpecifier.embedding\n                )\n                if response_vector_column_name is not None:\n                    column_renaming[response_vector_column_name] = \"response\"\n                    schema = replace(\n                        schema,\n                        response_column_names=EmbeddingColumnNames(\n                            vector_column_name=column_renaming[response_vector_column_name],\n                            raw_data_column_name=column_names_by_specifier.get(\n                                OpenInferenceSpecifier.default\n                            ),\n                        ),\n                    )\n                else:\n                    response_text_column_name = column_names_by_specifier.get(\n                        OpenInferenceSpecifier.default\n                    )\n                    if response_text_column_name is None:\n                        raise ValueError(\n                            \"invalid OpenInference format: missing text column for response\"\n                        )\n                    column_renaming[response_text_column_name] = \"response\"\n                    schema = replace(\n                        schema,\n                        response_column_names=column_renaming[response_text_column_name],\n                    )\n            elif group_name == \"prompt\":\n                prompt_vector_column_name = column_names_by_specifier.get(\n                    OpenInferenceSpecifier.embedding\n                )\n                if prompt_vector_column_name is None:\n                    raise ValueError(\n                        \"invalid OpenInference format: missing embedding vector column for prompt\"\n                    )\n                column_renaming[prompt_vector_column_name] = \"prompt\"\n                schema = replace(\n                    schema,\n                    prompt_column_names=RetrievalEmbeddingColumnNames(\n                        vector_column_name=column_renaming[prompt_vector_column_name],\n                        raw_data_column_name=column_names_by_specifier.get(\n                            OpenInferenceSpecifier.default\n                        ),\n                        context_retrieval_ids_column_name=column_names_by_specifier.get(\n                            OpenInferenceSpecifier.retrieved_document_ids\n                        ),\n                        context_retrieval_scores_column_name=column_names_by_specifier.get(\n                            OpenInferenceSpecifier.retrieved_document_scores\n                        ),\n                    ),\n                )\n            elif OpenInferenceSpecifier.embedding in column_names_by_specifier:\n                vector_column_name = column_names_by_specifier[OpenInferenceSpecifier.embedding]\n                column_renaming[vector_column_name] = group_name\n                embedding_feature_column_names = schema.embedding_feature_column_names or {}\n                embedding_feature_column_names.update(\n                    {\n                        group_name: EmbeddingColumnNames(\n                            vector_column_name=column_renaming[vector_column_name],\n                            raw_data_column_name=column_names_by_specifier.get(\n                                OpenInferenceSpecifier.raw_data\n                            ),\n                            link_to_data_column_name=column_names_by_specifier.get(\n                                OpenInferenceSpecifier.link_to_data\n                            ),\n                        )\n                    }\n                )\n                schema = replace(\n                    schema,\n                    embedding_feature_column_names=embedding_feature_column_names,\n                )\n            elif len(open_inference_columns) == 1:\n                open_inference_column = open_inference_columns[0]\n                raw_column_name = open_inference_column.full_name\n                column_renaming[raw_column_name] = open_inference_column.name\n                if open_inference_column.category is OpenInferenceCategory.feature:\n                    schema = replace(\n                        schema,\n                        feature_column_names=(\n                            (schema.feature_column_names or []) + [column_renaming[raw_column_name]]\n                        ),\n                    )\n                elif open_inference_column.category is OpenInferenceCategory.tag:\n                    schema = replace(\n                        schema,\n                        tag_column_names=(\n                            (schema.tag_column_names or []) + [column_renaming[raw_column_name]]\n                        ),\n                    )\n                elif open_inference_column.category is OpenInferenceCategory.prediction:\n                    if open_inference_column.specifier is OpenInferenceSpecifier.score:\n                        schema = replace(\n                            schema,\n                            prediction_score_column_name=column_renaming[raw_column_name],\n                        )\n                    if open_inference_column.specifier is OpenInferenceSpecifier.label:\n                        schema = replace(\n                            schema,\n                            prediction_label_column_name=column_renaming[raw_column_name],\n                        )\n                elif open_inference_column.category is OpenInferenceCategory.actual:\n                    if open_inference_column.specifier is OpenInferenceSpecifier.score:\n                        schema = replace(\n                            schema,\n                            actual_score_column_name=column_renaming[raw_column_name],\n                        )\n                    if open_inference_column.specifier is OpenInferenceSpecifier.label:\n                        schema = replace(\n                            schema,\n                            actual_label_column_name=column_renaming[raw_column_name],\n                        )\n            else:\n                raise ValueError(f\"invalid OpenInference format: duplicated name `{group_name}`\")\n\n        return cls(\n            dataframe.rename(\n                column_renaming,\n                axis=1,\n                copy=False,\n            ),\n            schema,\n        )\n</code></pre>"}, {"location": "inferences/#inferences.inferences.Inferences-functions", "title": "Functions", "text": ""}, {"location": "inferences/#inferences.inferences.Inferences.from_name", "title": "<code>from_name(name)</code>  <code>classmethod</code>", "text": "<p>Retrieves a dataset by name from the file system</p> Source code in <code>inferences/inferences.py</code> <pre><code>@classmethod\ndef from_name(cls, name: str) -&gt; \"Inferences\":\n    \"\"\"Retrieves a dataset by name from the file system\"\"\"\n    directory = DATASET_DIR / name\n    df = read_parquet(directory / cls._data_file_name)\n    with open(directory / cls._schema_file_name) as schema_file:\n        schema_json = schema_file.read()\n    schema = Schema.from_json(schema_json)\n    return cls(df, schema, name)\n</code></pre>"}, {"location": "inferences/#inferences.inferences.Inferences.to_disc", "title": "<code>to_disc()</code>", "text": "<p>writes the data and schema to disc</p> Source code in <code>inferences/inferences.py</code> <pre><code>def to_disc(self) -&gt; None:\n    \"\"\"writes the data and schema to disc\"\"\"\n    directory = DATASET_DIR / self.name\n    directory.mkdir(parents=True, exist_ok=True)\n    self.dataframe.to_parquet(\n        directory / self._data_file_name,\n        allow_truncated_timestamps=True,\n        coerce_timestamps=\"ms\",\n    )\n    schema_json_data = self.schema.to_json()\n    with open(directory / self._schema_file_name, \"w+\") as schema_file:\n        schema_file.write(schema_json_data)\n</code></pre>"}, {"location": "schema/", "title": "Schema", "text": ""}, {"location": "schema/#inferences.schema-classes", "title": "Classes", "text": ""}, {"location": "schema/#inferences.schema.EmbeddingColumnNames", "title": "<code>EmbeddingColumnNames</code>  <code>dataclass</code>", "text": "<p>A dataclass to hold the column names for the embedding features. An embedding feature is a feature that is represented by a vector. The vector is a representation of unstructured data, such as text or an image</p> Source code in <code>inferences/schema.py</code> <pre><code>@dataclass(frozen=True)\nclass EmbeddingColumnNames(Dict[str, Any]):\n    \"\"\"\n    A dataclass to hold the column names for the embedding features.\n    An embedding feature is a feature that is represented by a vector.\n    The vector is a representation of unstructured data, such as text or an image\n    \"\"\"\n\n    vector_column_name: str\n    raw_data_column_name: Optional[str] = None\n    link_to_data_column_name: Optional[str] = None\n</code></pre>"}, {"location": "schema/#inferences.schema.RetrievalEmbeddingColumnNames", "title": "<code>RetrievalEmbeddingColumnNames</code>  <code>dataclass</code>", "text": "<p>A relationship is a column that maps a prediction to another record.</p> Example <p>For example, in context retrieval from a vector store, a query is embedded and used to search for relevant records in a vector store. In this case you would add a column to the dataset that maps the query to the vector store records. E.x. [document_1, document_5, document_3]</p> <p>A table view of the primary dataset could look like this:</p> query retrieved_document_ids document_relevance_scores ... [doc_1, doc_5, doc_3] [0.4567, 0.3456, 0.2345] ... [doc_1, doc_6, doc_2] [0.7890, 0.6789, 0.5678] ... [doc_1, doc_6, doc_9] [0.9012, 0.8901, 0.0123] <p>The corresponding vector store dataset would look like this:</p> id embedding_vector document_text doc_1 ... lorem ipsum doc_2 ... lorem ipsum doc_3 ... lorem ipsum <p>To declare this relationship in the schema, you would configure the schema as follows:</p> <p>schema = Schema( ...     prompt_column_names=RetrievalEmbeddingColumnNames( ...         context_retrieval_ids_column_name=\"retrieved_document_ids\", ...         context_retrieval_scores_column_name=\"document_relevance_scores\", ...     ) ...)</p> Source code in <code>inferences/schema.py</code> <pre><code>@dataclass(frozen=True)\nclass RetrievalEmbeddingColumnNames(EmbeddingColumnNames):\n    \"\"\"\n    A relationship is a column that maps a prediction to another record.\n\n    Example\n    -------\n    For example, in context retrieval from a vector store, a query is\n    embedded and used to search for relevant records in a vector store.\n    In this case you would add a column to the dataset that maps the query\n    to the vector store records. E.x. [document_1, document_5, document_3]\n\n    A table view of the primary dataset could look like this:\n\n    | query | retrieved_document_ids | document_relevance_scores |\n    |-------|------------------------|---------------------------|\n    | ...   | [doc_1, doc_5, doc_3]  | [0.4567, 0.3456, 0.2345]  |\n    | ...   | [doc_1, doc_6, doc_2]  | [0.7890, 0.6789, 0.5678]  |\n    | ...   | [doc_1, doc_6, doc_9]  | [0.9012, 0.8901, 0.0123]  |\n\n\n    The corresponding vector store dataset would look like this:\n\n    |    id    | embedding_vector | document_text |\n    |----------|------------------|---------------|\n    | doc_1    | ...              | lorem ipsum   |\n    | doc_2    | ...              | lorem ipsum   |\n    | doc_3    | ...              | lorem ipsum   |\n\n\n    To declare this relationship in the schema, you would configure the schema as follows:\n\n    &gt;&gt;&gt; schema = Schema(\n    ...     prompt_column_names=RetrievalEmbeddingColumnNames(\n    ...         context_retrieval_ids_column_name=\"retrieved_document_ids\",\n    ...         context_retrieval_scores_column_name=\"document_relevance_scores\",\n    ...     )\n    ...)\n    \"\"\"\n\n    context_retrieval_ids_column_name: Optional[str] = None\n    context_retrieval_scores_column_name: Optional[str] = None\n</code></pre>"}, {"location": "schema/#inferences.schema.Schema", "title": "<code>Schema</code>  <code>dataclass</code>", "text": "Source code in <code>inferences/schema.py</code> <pre><code>@dataclass(frozen=True)\nclass Schema:\n    prediction_id_column_name: Optional[str] = None\n    id_column_name: Optional[str] = None  # Syntax sugar for prediction_id_column_name\n    timestamp_column_name: Optional[str] = None\n    feature_column_names: Optional[List[str]] = None\n    tag_column_names: Optional[List[str]] = None\n    prediction_label_column_name: Optional[str] = None\n    prediction_score_column_name: Optional[str] = None\n    actual_label_column_name: Optional[str] = None\n    actual_score_column_name: Optional[str] = None\n    prompt_column_names: Optional[Union[EmbeddingColumnNames, RetrievalEmbeddingColumnNames]] = None\n    response_column_names: Optional[Union[str, EmbeddingColumnNames]] = None\n    # document_column_names is used explicitly when the schema is used to capture a corpus\n    document_column_names: Optional[EmbeddingColumnNames] = None\n    embedding_feature_column_names: Optional[EmbeddingFeatures] = None\n    excluded_column_names: Optional[List[str]] = None\n\n    def __post_init__(self) -&gt; None:\n        # re-map document_column_names to be in the prompt_column_names position\n        # This is a shortcut to leverage the same schema for model and corpus datasets\n        if self.document_column_names is not None:\n            object.__setattr__(self, \"prompt_column_names\", self.document_column_names)\n            object.__setattr__(self, \"document_column_names\", None)\n\n        if self.id_column_name is not None:\n            object.__setattr__(self, \"prediction_id_column_name\", self.id_column_name)\n            object.__setattr__(self, \"id_column_name\", None)\n\n    def replace(self, **changes: Any) -&gt; \"Schema\":\n        return replace(self, **changes)\n\n    def asdict(self) -&gt; Dict[str, str]:\n        return asdict(self)\n\n    def to_json(self) -&gt; str:\n        \"Converts the schema to a dict for JSON serialization\"\n        return json.dumps(asdict(self))\n\n    @classmethod\n    def from_json(cls, json_string: str) -&gt; \"Schema\":\n        json_data = json.loads(json_string)\n\n        # parse embedding_feature_column_names\n        if json_data.get(\"embedding_feature_column_names\") is not None:\n            embedding_feature_column_names = {}\n            for feature_name, column_names in json_data[\"embedding_feature_column_names\"].items():\n                embedding_feature_column_names[feature_name] = EmbeddingColumnNames(\n                    vector_column_name=column_names[\"vector_column_name\"],\n                    raw_data_column_name=column_names[\"raw_data_column_name\"],\n                    link_to_data_column_name=column_names[\"link_to_data_column_name\"],\n                )\n            json_data[\"embedding_feature_column_names\"] = embedding_feature_column_names\n\n        # parse prompt_column_names\n        if (prompt := json_data.get(\"prompt_column_names\")) is not None:\n            json_data[\"prompt_column_names\"] = RetrievalEmbeddingColumnNames(\n                vector_column_name=prompt.get(\"vector_column_name\"),\n                raw_data_column_name=prompt.get(\"raw_data_column_name\"),\n                context_retrieval_ids_column_name=prompt.get(\"context_retrieval_ids_column_name\"),\n                context_retrieval_scores_column_name=prompt.get(\n                    \"context_retrieval_scores_column_name\"\n                ),\n            )\n\n        # parse response_column_names\n        if isinstance(json_data.get(\"response_column_names\"), Mapping):\n            response_column_names = EmbeddingColumnNames(\n                vector_column_name=json_data[\"response_column_names\"][\"vector_column_name\"],\n                raw_data_column_name=json_data[\"response_column_names\"][\"raw_data_column_name\"],\n            )\n            json_data[\"response_column_names\"] = response_column_names\n\n        return cls(**json_data)\n</code></pre>"}, {"location": "schema/#inferences.schema.Schema-functions", "title": "Functions", "text": ""}, {"location": "schema/#inferences.schema.Schema.to_json", "title": "<code>to_json()</code>", "text": "<p>Converts the schema to a dict for JSON serialization</p> Source code in <code>inferences/schema.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"Converts the schema to a dict for JSON serialization\"\n    return json.dumps(asdict(self))\n</code></pre>"}]}